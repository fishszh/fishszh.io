---
title: 贝叶斯分类器
keywords: [机器学习, 贝叶斯分类器]
date: 2019-10-09
weight: 60
markup: mmark
toc: true  # Show table of contents? true/false
type: docs  # Do not modify.
menu:
    learning-machineLearning:
---
---
## 贝叶斯决策论

贝叶斯决策论(Bayesian decision theory)是概率框架下实施决策的基本方法.对分类任务来说,在所有相关概率都已知的理想情形下,贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记.下面我们以多分类任务为例来解释其基本原理.  

假设有$N$种可能的类别标记,即 $\mathcal{Y} = {c\_1,c\_2,\ldots,c\_N}$,$\lambda_{ij}$ 是将一个真实标记为$c_j$的样本误分类为$c_i$所产生的损失.基于后验概率$P(c_i|x)$可获得将样本$x$分类为$c_i$所产生的**期望损失**(excepted loss),即在样本$x$上的'**条件风险**'(conditional risk)

$$R(c_i|x)=\sum_{j=1}^{N}\lambda_{ij}P(c_j|x)$$

我们的任务是寻找一个判定准则$h$ : $\mathcal{X}\mapsto \mathcal{Y}$以最小化总体风险

$$R(h) = \mathbb{E}_x \left[ R \left( h(x) |x \right) \right]$$

显然,对每个样本$x$,若$h$能最小化条件风险$R \left( h(x) |x \right)$,则总体风险$R(h)$也将被最小化.这就产生了**贝叶斯判定准则(Bayes decision rule)**:为最小化总体风险,只需在每个样本上选择那个能使条件风险$R(c|x)$最小的类别标记,即

 $$h^*(x) = \arg \min_{c \in \mathcal{Y}} R(c|x)$$

此时,$h^{\*}$称为**贝叶斯最优分类器(Bayes optimal classifier)**,与之对应的总体风险$R(h^\*)$称为**贝叶斯风险(Bayes risk)**.$1-R(h^\*)$反映了分类器所能达到的最好性能,即通过机器学习所能产生的模型精度的理论上限.

具体来说如果目标是最小化分类错误率,则误判损失$\lambda_{ij}$可写为

$$
\begin{cases}
\lambda_{ij}=
0, & if \quad i=j; \\
1, & otherwise  \\
\end{cases}$$

此时条件风险

$$R(c|x)=1-P(c|x)$$

于是,最小化分类错误率的贝叶斯最优分类器为

$$h^*(x) = \arg \max_{c \in \mathcal{Y}} P(c|x)$$

即对每个样本$x$,选择能使后验概率$P(c|x)$最大的类别标记.

不难看出,欲使用贝叶斯判定准则来最小化决策风险,首先要获得后验概率$P(c|x)$.然而,在现实生活中这通常难以直接获得.从这个角度来看,机器学习所要实现的是基于有限的训练样本集尽可能准确地估计出后验概率$P(c| x)$,这样得到的是'**生成式模型'(generative models)**.显然,前面介绍的决策树,BP神经网络,支持向量机等,都可归入判别式模型的范畴.对生成式模型来说,必然考虑

$$P(c|x)=\frac{P(x,c)}{P(x)}$$

基于贝叶斯定理,$P(c|x)$可写为

$$P(c|x) = \frac{P( c ) P(x|c)}{P(x)}$$

其中,$P( c )$是类'**先验**'(prior)概率,$P(c|x)$是样本$x$相对于类标记$c$的**类条件概率(class-conditional probality)**,或称为'**似然'(likelihood)**;$P( x )$是用于归一化的'**证据**'(evidence)因子.对给定样本$x$,证据因子$P(x)$与类标记无关,因此估计$P(c|x)$的问题就转化为如何基于训练数据$D$来估计先验$P( c )$和似然$P(x|c)$.

类先验概率$P( c )$表达了样本空间中各类样本所占的比例,根据大数定律,当训练集包含充足的独立同分布样本时,$P( c )$可通过各类样本出现的频率来进行估计.

对类条件概率$P(x|c)$来说,由于它涉及关于$x$所有属性的联合概率,直接根据样本出现的频率来估计将会遇到严重的困难.例如,假设样本的d个属性都是二值的,则样本空间将有$2^d$种可能的取值,在现实应用中,这个值往往远大于训练样本数$m$,也就是说,很多样本取值在训练集中根本没有出现,直接使用频率来估计$P(x|c)$显然不可行,因为'未被观测到'与'出现概率为零'通常是不同的.

## 极大似然估计

估计类条件概率的一种常用策略是先假定其具有确定的概率分布形式,再基于训练样本对概率分布的参数进行估计,具体的,记关于类别$c$的类条件概率为$P(x|c)$,假设$P(x|c)$具有确定的形式并且被参数向量$\theta_{c}$唯一确定,则我们的任务就是利用训练集$D$估计参数$\theta_c$.为明确起见,我们将$P(x|c)$记为$P(x|\theta_c)$.

事实上,概率模型的训练过程就是参数估计(parameter estimation)过程.对于参数估计,统计学界的两个学派分别提供了不同的解决方案:**频率主义学派**认为参数虽然未知,但却是客观存在的固定值,因此,可通过优化似然函数等准则来确定参数值;贝叶斯学派则认为参数是未观察到的随机变量,其本身也可有分布,因此,可假定参数服从一个先验分布,然后基于观测到的数据来计算参数的后验分布.本节介绍源自频率注意学派的**极大似然估计**(Maximum Likelihood Estimation,简称MLE),这是根据数据采样来估计概率分布参数的经典方法.

令$D_c$表示训练数据集$D$中第$c$类样本组成的集合,假设这些样本是独立同分布的,则参数$\theta_c$对于数据集$D_c$的似然是

$$P(D_c|\theta_c) = \prod_{x \in D_c} P(x|\theta_c)$$

对$\theta_c$进行极大似然估计,就是取寻找能最大化似然$P(D_c|\theta_c)$的参数值$\hat{\theta}_c$.直观上看,极大似然估计是试图在$\theta_c$所有可能的取值中,找到一个能使数据出现的'可能性'最大的值.

上式中的连乘操作易造成下溢,通常使用对数似然(log-likelihood)

$$\begin{align}
LL(\theta_c) & = \log P(D_c | \theta_c)  \\
& = \sum_{x\in D_c} \log P(x | \theta_c)
\end{align}$$

此时参数$\theta_c$的极大似然估计$\hat{\theta}_c$为

$$\hat{\theta}_c = \arg \max_{\hat{\theta}_c} LL(\theta_c)$$
例如,在连续属性情形下,假设概率密度函数$$p(x|c)\sim\mathcal{N}(\mu_c,\sigma^2_c)$$,则参数$\mu_c$和$\sigma^2_c$的极大似然估计为

$$
\begin{align}
\hat{\mu}_c & = \frac{1}{|D_c|}\sum_{x\in D_c} x , \\
\hat{\sigma}^2_c & = \frac{1}{|D_c|}\sum_{x\in D_c} (x-\hat{\mu}_c)(x-\hat{\mu}_c)^T .
\end{align}
$$

也就是说,通过极大似然法得到的正态分布均值就是样本均值,方差就是$(x-\hat{\mu}_c)(x-\hat{\mu}_c)^T$的均值,这显然是一个符合直觉的结果.在离散属性情形下,也可通过类似的方式估计条件概率.

需要注意的是,这种参数化的方法虽能是类条件概率估计变得相对简单,但估计结果的准确性严重依赖于所假设的概率分布形式是否符合潜在的真实数据分布.在现实应用中,欲做出能较好地接近潜在真实分布的假设,往往需在一定程度上利用应用任务本身的经验知识,否则若仅凭'猜测'来假设概率分布形式,很可能产生误导性的结果.

## 朴素贝叶斯分类器

不难发现,基于贝叶斯公式来估计后延概率$P(c|x)$的主要困难在于:类条件概率$P(x|c)$是所有属性上的联合概率,难以从有限的训练样本直接估计而得.为避开这个障碍,**朴素贝叶斯分类器**(naive Bayes classifier)采用了'**属性条件独立假设**'(attribute conditional independence assumption):对已知类别,假设所有属性相互独立.换言之,假设每个属性独立地对分类结果发生影响.

基于属性条件独立假设,

$$P(c|x) = \frac{P( c )P(x|c)}{P(x)}=\frac{P( c )}{P(x)}\prod_{i=1}^{d}P(x_i|c)$$

其中$d$为属性数目,$x_i$为$x$在第$i$个属性上的取值.

由于对所有类别来说$P(x)$相同,因此贝叶斯判定准则有

$$h_{nb}(x) = \arg \max_{c\in \mathcal{Y}} P(c)\prod_{i=1}^d P(x_i|c),$$

这就是朴素贝叶斯分类器的表达式.

显然,朴素贝叶斯分类器的训练过程就是基于训练集$D$来估计类先验概率$P(c)$,并为每个属性估计条件概率$P(x_i|c)$.

令$D_c$表示训练集$D$中$c$类样本组成的集合,若有充足的独立同分布样本,则可容易地估计出类先验概率

$$P( c )=\frac{D_c}{D}$$

对离散属性而言,令$D_{c,x_i}表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合,则条件概率$P(x_i|c)$可估计为

$$P( x_i|c ) = \frac{|D_{c,x_i}|}{|D_c|}$$

对连续属性可考虑概率密度函数,假定$$p(x_i|c)\sim\mathcal{N}(\mu_{c,i},\sigma_{c,i}^2)$$,其中$\mu_{c,i}$和$\sigma^2_{c,i}$分别是第$c$类样本在第$i$个属性上去之的均值和方差,则有

$$p(x_i|c) = \frac{1}{\sqrt{2\pi}\sigma_{c,i}}\exp\left(-\frac{(x_i-\mu_{c,i})^2}{2\sigma^2_{c,i}}\right)$$

## 半朴素贝叶斯分类器

为了降低贝叶斯公式中估计后验概率的困难$P(c|x)$的困难,朴素贝叶斯分类器采用了属性条件独立性假设,但在现实任务中这个假设往往很难成立.于是,人们尝试对属性条件独立性假设进行一定的放松,由此产生了一类称为'**半朴素贝叶斯分类器**'(semi-naive Bayes classifier)的学习方法.

半朴素贝叶斯分类器的基本想法是适当考虑一部分属性间的相互依赖信息,从而既不需要进行完全联合概率计算,又不至于彻底忽略了比较强的属性依赖关系.'**独立依赖估计**'(One-Dependent Estimator,简称ODE)半朴素贝叶斯分类器最常用的一种策略.顾名思义,所谓'独依赖'就是假设每个属性在类别之外最多依赖于一个其他属性,即

$$P(c|x)\propto P(c)\prod_{i=1}^d P(x_i|c,pa_i)$$

其中$pa_i$为属性$x_i$所依赖的属性,称为$x_i$的父属性.此时,对每个属性$x_i$,若其父属性$pa_i$已知,则可采用类似**估计概率值$P(x_i|c,pa_i)$.于是,问题的关键就转化为如何确定每个属性的父属性,不同的做法产生不同的独依赖分类器.

最直接的做法是假设所有属性都依赖于同一个属性,称为'超父'(super-parent),然后通过交叉验证等模型选择方法来确定超父属性,由此形成了SPODE(Super-Parent ODE)方法.

TAN(Tree Augmened naive Bayes)则是在最大带权生成树(maximum weighted spanning tree)算法的基础上,通过以下步骤将属性间依赖关系简约的树形结构:

(1) 计算任意两个属性之间的条件互信息(conditional mutual information)

$$I(x_i,x_j|y) = \sum_{x_i,x_j; c\in\mathcal{Y}} P(x_i,x_j|c)\log \frac{P(x_i,x_j|c)}{P(x_i|c)P(x_j|c)}$$

(2) 以属性为节点构建完全图,任意两个结点之间边的权重设为$I(x_i,x_j|y)$;  
(3) 构建此完全图的最大带权生成树,挑选根变量,将边置为有向;  
(4) 加入类别结点$y$,增加从$y$到每个属性的有向边.  

容易看出,条件互信息$I(x_i,x_j|y)$刻画了属性$x_i$和$x_j$在已知类别情况下的相关性,因此,通过最大生成树算法,TAN 实际上仅保留了强相关属性之间的依赖性.

AODE(Average One-Dependent Estimator)是一种基于集成学习机制,更为强大的独依赖分类器.与SPODE通过模型选择确定超父属性不同,AODE尝试将每个属性作为超父来构建SPODE,然后将那些就有足够训练数据支撑的SPODE集成起来作为最终结果,即

$$P(c|x) \propto \sum_{i=1,|D_{x_i}| \ge m^{'}}^{d} P(c|x_i) \prod _{j=1}^d P(x_j|c,x_i)$$

其中$D_{x_i}$是在第$i$个属性上取值为$x_i$的样本的集合,$m^{'}$为阈值常数.显然AODE需估计$P(c|x_i)$和$P(x_j|c,x_i)$.

$$\hat{P}(c,x_i) = \frac{|D_{c,x_i}|+1}{|D|+N\times N_i}$$

$$\hat{P}(x_j|c,x_i) = \frac{|D_{c,x_i,x_j}|+1}{|D_{c,x_i}|+N_j}$$

其中$N$是$D$中可能的类别数,$$N_i$$是第$i$个属性可能的取值数,$D_{c,x_i}$是类别为$c$且在第$i$个属性上取值为$$x_i$$的样本集合,$$D_{c,x_i,x_j}$$是类别为$c$且在第$i$和第$j$个属性上取值分别为$x_i$和$x_j$的样本集合.

不难看出,与朴素贝叶斯分类器类似,AODE的训练过程也是'计数',即在训练数据集上对符合条件的样本进行计数的过程.与朴素贝叶斯分类器相似,AODE无需模型选择,既能通过预计算节省预测时间,也能采取懒惰学习方式在预测时再进行计数,并且易于实现增量学习.

依然将属性条件独立性假设放松为独依赖假设可能获得泛化性能的提升,那么,能否通过考虑属性间的高阶依赖来进一步提升泛华性能呢?也就是说`

## 贝叶斯网

**贝叶斯网**(Bayesian network) 亦称'信念网'(belief network),它借助有向无环图(Directed Acyclic Graph,简称DAG)来刻画属性之间的依赖关系,并使用条件概率表(Conditional Probability Table,简称CPT)来描述属性的联合概率分布.

具体来说,一个贝叶斯网$B$由结构$G$和参数$\Theta$两部分构成,即$B=\langle G,\Theta\rangle$.网络结构$G$是一个有向无环图,其每个节点对英语一个属性,若两个属性有直接依赖关系,则他们由一条边连接起来;参数$\Theta$定量描述这种依赖关系,假设属性$x_{i}$在$G$中的父节点集为$\pi_{i}$,则$\Theta$包含了每个属性的条件概率$\theta_{x_i}|\pi_i=P_B(x_i|\pi_i)$
### 结构

贝叶斯网结构有效的表达了属性间的条件独立性.给定父节点集,贝叶斯网假设每个属性与它的非后裔属性独立,于是$B=\langle G, \Theta \rangle$将属性$x_1,x_2,\ldots,x_d$的联合概率分布定义为


$$
P_B(x_1,x_2,\ldots,x_d) = \prod_{i=1}^d P_B(x_i|\pi_i)= \prod_{i=1}^d \theta_{x_i}|\pi_i \tag{1} \label{1}
$$

在'同父'(common parent)结构中,给定父节点$x_1$的取值,则$x_3$与$x_4$条件独立.在'顺序'结构中,给定$x$的值,则$y$与$z$条件独立.$V$型结构(V-structure)亦称'冲撞'结构,给定子节点$x_4$的取值,$x_1$与$x_2$比不独立;奇妙的是,若$x_4$的取值完全未知,则$V$型结构下$x_1$与$x_2$却是相互独立的.我们做一个简单的验证:

$$\begin{align}
P(x_1,x_2) & = \sum_{x_4} P(x_1,x_2,x_4)  \\
& = \sum_{x_4} P(x_4|x_1,x_2)P(x_1)P(x_2)  \\
& = P(x_{i})P(x_2)  \\
\end{align}$$

这样的独立性称为'边际独立性'(marginal independence),记为$x_1\bot  x_2$

事实上,一个变量取值的确定与否,能对另两个变量间的独立性发生影响,这个现象并非$V$型结构所特有.例如在同父结构中,条件独立性$x_3\bot x_4 \|x_1$成立,但$x_1$的取值未知,则$x_3$和$x_4$就不独立,即$x_3 \bot x_4$不成立;在顺序结构中,$y \bot z | x$,但 $y\bot z$不成立.

为了分析有向图中变量间的条件独立性,可使用"有向分离"(D-separation).我们先把有向图转变成为一个无向图:

- 找出有向图中的所有$V$型结构,在$V$型结构的两个父节点之间加上一条无向边;
- 将所有有向边改为无向边

由此产生的无向图称为"道德图"(moral graph),另父节点相连的过程称为"道德化"(moralization).

基于道德图能直观,迅速地找到变量间的条件独立性.假定道德图中有变量$x,y$和变量集合$z=\\{z_i\\}$,若变量$x$和$y$能在图上被$\bf z$分开,即从道德图中将变量集合$\bf z$去除后,$x$和$y$分属两个连通分支,则称变量$x$和$y$被$\bf z$有向分离,即$x\bot y | \bf z$成立.

### 学习

若网络结构已知,即属性间的依赖关系已知,则贝叶斯网的学习过程相对简单,只需通过对训练样本"计数",估计出每个结点的条件概率表即可.但在现实应用中我们往往并不知道网络结构,于是,贝叶斯网学习的首要任务就是根据训练数据集来找出结构最'恰当'的贝叶斯网."评分搜索"是求解这一问题常用的方法.具体来说,我们先定义一个评分函数(source function),以此来评估贝叶斯网与训练数据的契合程度,然后基于这个评分函数来寻找结构最优的贝叶斯网.显然,评分函数引入了关于我们希望获得什么样的贝叶斯网的归纳偏好.

常用评分函数通常基于信息论准则,此类准则将学习问题看作一个数据压缩任务,学习的目标是找到一个能以最短编码长度和使用该模型描述数据所需的字节长度.对贝叶斯网学习而言,模型就是一个贝叶斯网,同时,每个贝叶斯网描述了一个在训练数据上的概率分布,自有一套编码机制能使那些经常出现的样本有更短的编码.于是,我们应选择那个综合编码长度(包括描述网络和编码数据)最短的贝叶斯网,这就是"最小描述长度"(Minimal Description Length, 简称MDL)准则.

给定训练集$D=\\{x_1,x_2,\ldots,x_m\\}$,贝叶斯网$B=\langle G,  \Theta \rangle$在$D$上的评分函数可写为

$$
s(B|D)=f(\theta)|B|-LL(B|D)\tag{2}\label{2}
$$

其中,$|B|$是贝叶斯网的参数个数;$f(\theta)$表示描述每个参数$\theta$所需的自己数;而

$$
LL(B|D) = \sum_{i=1}^{m}\log P_B(x_i) \tag{3}\label{3}
$$

是贝叶斯网$B$的对数似然.显然,式$\eqref{2}$的第一项是计算编码贝叶斯网$B$所需的字节数,第二项是计算$B$所对应的概率分布$P_B$对$D$描述得有多好.于是学习任务就转化为一个优化任务,即寻找一个贝叶斯网$B$使评分函数$s(B|D)$最小. 

若 $f(\theta)=1$,即每个参数用1字节描述,则得到$AIC $(Akaike Information Criterion)评分函数

$$AIC (B|D) = |B| - LL(B|D)$$

若 $f(\theta)=\frac{1}{2}\log m$,即每个参数用$\frac{1}{2}\log m$字节描述,则得到$BIC $(Bayesian Information Criterion)评分函数

$$BIC (B|D) = \frac{\log m}{2}|B| - LL(B|D)$$

显然,若$f(\theta)=0$,即不计算对网络进行编码的长度,则评分函数退化为负对数似然,相应的,学习任务对话为极大似然估计.  
不难发现,若贝叶斯网$B=\langle G,  \Theta \rangle$的网络结构$G$固定,则评分函数$s(B|D)$的第一项为常数.此时,最小化$s(B|D)$等价于对参数$\Theta$的极大似然估计.由式\eqref{3}和\eqref{1}可知,参数$\theta_{x_i}|\pi_i$能直接在训练数据$D$上通过经验估计获得,即

$$\theta_{x_i|\pi_i} = \hat{P}_{D}(x_i|\pi_i)$$

其中$\hat{P}_{D}(\bullet)$是$D$上的经验分布.因此,为了最小化评分函数$s(B|D)$,只需要对网络结构进行搜索,而候选结构的最有参数可直接在训练集上计算得到.

不幸的是,从所有可能的网络结构搜索最优贝叶斯结构是一个$NP$难问题,难以快速求解.有两种常用的策略能在有限时间内丘的近似解:第一中是贪心法,例如从某个网络结构出发,每次调整一条边(增加,删除或调整方向),直到评分函数值不在降低为止;第二种是通过给网络结构施加约束来削减搜索空间,例如将网络结构限定为树形结构等.

### 推断

贝叶斯网训练好之后就能用来回答"查询"(query),即通过一些属性变量的观测值来推断其他属性变量的取值.  
最理想的是直接根据贝叶斯网络定义的联合概率分布来紧缺计算后验概率,不幸的是,这样的"精确推断"已被证明是$\rm NP$难的;换言之,当网络结点较多,连接稠密时,难以进行精确推断,此时需借助"近似推断",通过降低精度要求,在有限时间内求得近似解.在现实应用中,贝叶斯网的近似推断常使用吉布斯采样(Gibbs sampling)来完成,这是一种随机采样方法,我们来看看他是如何工作的.  
令$Q=\{Q_{1},Q_{2},\ldots,Q_{n}\}$,表示待查变量,$E=\{E_{1},E_{2},\ldots,E_{n}\}$为证据变量,已知其取值为$e=\{e_{1},e_{2},\ldots,e_{n}\}$.目标是计算后验概率$P(Q=q|E=e)$,其中$q=\\{q_{1},q_{2},\ldots,q_{n}\\}$是待查询变量的一组取值.

吉布斯采样算法先随机产生一个与证据$E=e$一致的样本$$q^0$$作为初始点,然后每部从当前样本出发产生下一个样本.具体来说,在第$t$次采样中,算法先假设$q^{t}=q{t-1}$,然后对非证据变量逐个进行采样改变其取值,采样概率根据贝叶斯网$B$和其他变量的当前取值(即$Z=z$)计算获得.假定经过$T$次采样得到的与$q$一致的样本共有$n_q$个,则可近似估算出后验概率

$$P(Q=q|E=e)\simeq\frac{n_q}{T} \tag{4}\label{4}$$

实质上,吉布斯采样是在贝叶斯网所有变量的联合概率状态空间与证据$E=e$一致的子空间进行"随机漫步"(random walk).每一步仅依赖于前一步的状态,这是一个"马尔科夫链"(Markov Chain).在一定条件下,无论从什么初始状态开始,马尔科夫链第$t$步的状态分布在$t\to \infty$时比收敛于一个平稳分布(stationary distribution);对于吉布斯采样来说,这个分布恰好是$P(Q|E=e)$.因此,在$T$很大时,吉布斯采样相当于根据$P(Q|E=e)$采样,从而保证了式\eqref{4}收敛于$P(Q=q|E=e)$.

---
**输入**: 

贝叶斯网$B=\langle G,  \Theta \rangle$  

&nbsp 采样次数$$T$$;  

证据变量$E$及其取值$e$;  

待查询变量$Q$及其取值$q$  

**过程**: 

1. $n_q = 0$
2. $q^0=$ 对$Q$随机赋初始值
3. for $t=1,2,\ldots,T$ do
4. $\quad$ for $Q_i \in Q$ do
5. $\quad  \quad Z = E \cup Q  \\{Q_i\\}$
6. $\quad  \quad z = e \cup q^{t-1}  \\{q_i^{t-1}\\}$
7. $\quad  \quad$根据$B$计算分布$P_B(Q_i|Z=z)$
8. $\quad  \quad q_i^t=$根据$P_B(Q_i|Z=z)$采样所获$Q_i$取值
9. $\quad  \quad$ $$q^{t}=$$将$$q^{t-1}$$中的$$q_{i}^{t-1}$$用$$q_i^t$$替换
10. $\quad  \quad$ end for
11. if $q^t=q$ then
12. $\quad  \quad n_q=n_q+1$
13. end if
14. end for
15. **输出**: $P(Q=a|E=e)\simeq\frac{n_q}{T}$
---

需要注意的是,由于马尔科夫链通常需要很长时间才能趋于平稳分布,因此吉布斯采样算法的收敛速度较慢.此外,贝叶斯网中存在极端概率"0"或者"1",则不能保证马尔科夫链存在平稳分布,此时吉布斯采样会给出错误的估计结果.

## EM算法

在前面的讨论中,我们一直假设训练样本所有属性变量的值都已被观测到,既训练样本是完整的.但在现实应用中往往会遇到"不完整"的训练样本,属性变量值未知.在这种存在"未观测"变量的情形下,是否仍能对模型进行估计呢?

未观测变量的学名是"隐变量"(latent variable).令$X$表示已观测变量集,$Z$表示隐变量集,$\Theta$表示模型参数.若欲对$\Theta$做极大似然估计,则应最大化对数似然

$$LL(\Theta|X,Z) = \ln P(X,Z|\Theta)$$

然而由于$Z$是隐变量,上式无法直接求解.此时我们可通过对$Z$计算期望,来最大化已观测数据的对数"边际似然"(marginal likelihood)

$$LL(\Theta|X) = \ln P(X|\Theta) = \ln \sum_{z} P(X,Z|\Theta)$$

EM(Experience-Maximumization)算法是常用的估计参数隐变量的利器,它是一种迭代式的方法,其基本想法是:若参数$\Theta$已知,则可方便地对参数$\Theta$做极大似然估计$M$步.

于是,以初始值$\Theta^0$为起点,对上式,可迭代执行以下步骤直至收敛:

- 基于$$\Theta^{t}$$推断隐变量$Z$的期望,记为$Z^t$;
- 基于已观测变量$X$和$$Z^t$$对参数$\Theta$做极大似然估计,记为$\Theta^{t+1}$;

这就是EM算法的原型.

进一步,若我们不是取$Z$的期望,而是基于$$\Theta^{t}$$计算隐变量$Z$的概率分布$P(Z|X,\Theta^{t})$,则EM算法的两个步骤是:

- $E$步(Expectation): 以当前参数$\Theta^{t}$推断隐变量分布$P(Z|X,\Theta^{t})$,并计算对数似然$$LL(\Theta|X,Z)$$关于$Z$的期望

$$Q(\Theta|\Theta^{t}) = \Bbb{E}_{Z|X,\Theta^{t}}LL(\Theta|X,Z)$$

- $M$步(Maximumization): 寻找参数最大化期望似然,即

$$\Theta^{t+1} = \arg \max \quad Q(\Theta|\Theta^{t})$$

简单来说,EM算法使用两个步骤交替计算:第一步是期望$(E)$步,利用当前估计的参数值来计算对数似然的期望值;第二步是最大化(M)步,寻找能使E步产生的似然期望最大化的参数值.然后,新得到的参数值重新被用于E步,$\cdots$直至收敛到局部最优解.

事实上,隐变量估计问题也可以通过梯度下降等优化算法求解,但由于求和的项数将随着隐变量的数目以指数级上升,会给梯度计算带来麻烦;而EM算法则可看做一种帝都优化方法.
