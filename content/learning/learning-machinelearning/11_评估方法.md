---
title: 评估方法
date: 2019-08-21
keywords: [机器学习, 模型评估]
weight: 11
markup: mmark
toc: true  # Show table of contents? true/false
type: docs  # Do not modify.
menu:
    learning-machineLearning:
      parent: 模型评估与选择
---
---
```
A[测试集] --> B[测试误差]
```

## 留出法(hold out)

直接将数据集$D$划分为两个互斥的集合,其中一个作为训练集$S$,用来评估测试误差.
另一个作为测试集$T$,用来计算泛化误差.

需要注意的是,训练/测试的划分要尽量保持数据分布的一致性,不免因数据划分过程引入额外的偏差
而对结果产生影响.

单次使用留出法得到的估计结果往往不够稳定,因使用留出法时,一般采用若干次随机划分,重复进行实验
评估后采取平均值作为最终的评估结果.

## 交叉验证法(cross validation)

先将数据集$D$ 划分为 $k$ 个大小相似的互斥子集,即 

$$D=D_{1}\cup D_{2}\cup\cdots \cup D_{k}, D_{i}\cap D_{j}=\varnothing $$


## 自助法(bootstrapping)

给定包含$m$个样本的的数据集$D$,我们对它进行采样产生数据集$D^{'}$:每次随机从$D$中挑选
一个样本,将其拷贝放入$D^{'}$, 然后再将该样本放回数据集$D$中,使得该样本在下次采集时仍
能被采集到,将这个过程重复$m$次.

### 优点

- 在数据集比较小,难以有效划分训练/测试集时很适用
- 能从初始数据集中产生多个不同的训练集,这对集成学习等方法有很大好处

### 缺点

- 改变了数据分布,会引入估计偏差.因此在数据量足够时,留出法和交叉验证法更常用一些.



