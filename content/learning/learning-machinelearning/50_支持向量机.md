---
title: 支持向量机
keywords: [机器学习, 支持向量机]
date: 2019-08-21
weight: 50
markup: mmark
toc: true  # Show table of contents? true/false
type: docs  # Do not modify.
menu:
    learning-machineLearning:
---
---
## 间隔与支持向量机

给定训练样本$D={(x_1,y_1),(x_2,y_2),...,(x_m,y_m)},y_i\in{-1,1}$,分类学习最基本的想法就是基于训练集D在样本空间中找到一个划分超平面,将不同类别的样本分开.

在样本空间中,划分超平面可通过如下线性方程来描述:

$$w^Tx+b=0$$

其中$w=(w_1,w_2,...,w_d)$为法向量,决定了超平面的方向,$b$为位移项,决定了超平面与原点之间的距离.显然,划分超平面可被法向量$w$和位移$b$确定.样本空间中任意点$x$到超平面$(w,b)$的距离可以写为

$$r=\frac{|w^Tx+b|}{|w|}$$

$$
\begin{cases}
w^T x_i +b \ge + 1, & y_i = +1   \\   
w^T x_i +b \le - 1, & y_i = -1   
\end{cases}
$$

距离超平面最近的这几个训练样本点使上式中等号成立,他们被称为`支持向量(support vector)`,两个异类支持向量到超平面的距离之和为:

$$\gamma = \frac{2}{\|w\|}$$

它被称之为**间隔(margin)**.  
欲找到具有**最大间隔**(maximum margin)的划分超平面,也就是要找到能满足上式中约束的参数$w$和$b$,使得$\gamma$最大,即

$$max(w,b)  \frac{2}{\|w\|}$$

显然,为了最大化间隔,仅需最大化$\|w\|^{-1}$,这等价于最小化$\|w\|^2$,于是上式可重新写为:

$$min(wb) \frac{1}{2}\|w\|^{2}$$

这就是**支持向量机(Support Vector Machine, SVM)**的基本型.

## 对偶问题

我们希望求解上式来得到最大间隔划分超平面所对应的模型

$$f(x) = w^T +b $$

注意到上式本身是一个图二次规划(convex quadratic programing)问题.

