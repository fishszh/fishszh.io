---
title: 神经网络
keywords: [机器学习, 神经网络]
date: 2019-08-21
weight: 40
markup: mmark
toc: true  # Show table of contents? true/false
type: docs  # Do not modify.
menu:
    learning-machineLearning:
---
---
## 神经元模型

神经网路(neural networks)方面的研究很早就已出现,今天"神经网络"已是一个相当大的,多科学交叉的学科领域.

神经网络是由具有适应性的简单单元组成的广泛并行互联的网络,它的组织能够模拟生物神经系统对其实世界物体所作出的交互反应.我们在机器学习中谈论神经网路时指的是'神经网络学习',或者说,是机器学习与神经网路这两个学科领域的交叉部分.  

神经网络中最基本的成分是**神经元**(neuron)模型,即上述定义中的'简单单元'.在生物神经网络中,每个神经元与其他神经元相连,当它'兴奋'时,就会向相连的神经元发送化学物质,从而改变这些神经元内的电位;如果某神经元的电位超过了一个阈值(threshold),那么他就会被激活,即'兴奋'起来,向其他神经元发送化学物质.

**M-P神经元模型**:神经元接受到来自n个其他神经元传递过来的输入信号,这些输入信号,这些输入信号通过带权重的连接(connection)进行传递,神经元接收到的总输入值将与神经元的阈值进行比较,然后通过`激活函数`(activation function)处理以产生神经元的输出.

理想中的激活函数是一种阶跃函数,它将输入值映射为输出值`0`或`1`,显然`1`对应于神经元兴奋,`0`对应于神经元抑制.然而,阶跃函数具有不连续,不光滑等不太好的性质,因此实际常用`Sigmoid`函数作为激活函数.  

把许多这样的神经元按一定的层次结构连接起来,就得到了神经网络.

## 感知机与多层网络

**感知机**(perception)由两层神经元组成,输入层接收外界输入信号后传递给输出层,输出层是M-P神经元,亦称'阈值逻辑单元'(threshold logic unit).

感知机能容易的实现逻辑与,或,非运算.注意到$y=f(\sum_{i}w_{i}x_{i}-\theta_{i})$,f是阶跃函数.  

- 与:$x_1 \land x_2$:令$w_1=w_2=1,\theta=2$,则$y=f(x_1+x_2-2)$,仅在$x_1=x_2=1$时,$y=1$;
- 或:$x_1 \vee x_2$:令$w_1=w_2=1,\theta=0.5$,则$y=f(x_1+x_2-0.5)$,当$x_1=1或x_2=1$时,$y=1$;
- 非:$\neg x_1$:令$w_1=-0.6,w_2=0,\theta=-0.5$,则$y=f(-0.6x_1+0 \cdot x_2+0.5)$,当$x_1=1$时,$y=0$,当$x_1=0$时,$y=1$;

更一般的,给定训练数据集,权重$$w_i(i=1,2,..,n)$$以及阈值$\theta$可以通过学习得到.阈值$$\theta$$可以看作一个固定输入为-1.0的哑节点(dummy node)所对应的连接权重$$w_{n+1}$$这样,权重和阈值学习就可统一为权重学习.

感知机的学习规则非常简单,对训练样例$(x,y)$,若当前感知机的输出为$\hat{y}$,则感知机权重这样调整:

$$
w_i \leftarrow w_i + \Delta w_i \\
\Delta w_i = \eta(y-\hat{y})x_i
$$

其中$\eta \in(0,1)$称为学习率(learning rate).若感知机对训练样例$(x,y)$预测正确,即$y=\hat{y}$,则感知机不发生变化,否则将根据错误的程度进行权重调整.

感知机只有输出层神经元进行激活函数处理,即只拥有一层功能神经元,其学习能力非常有限.事实上,上述与或非问题都是线性可分(linearly separable)的问题.若两问题实现性可分的,即存在一个线性超平面能将它们分开,则感知机学习过程一定会收敛(converge)而求得适当的权向量$w$,否则感知机学习过程将会发生振荡(fluctuation)$w$难以稳定下来,不能求得合适解.

要解决非线性可分问题,需要考虑使用多层功能神经元.两层感知机就可以解决疑惑问题.输出层与输入层之间的一层神经元,被称为因曾或者隐含层(hidden layer),隐含层和输出层神经元都是拥有激活函数的功能神经元.

更一般的神将网络是多层级结构,每层神经元与下一层神经元全互连,神经元之间不存在同层连接,也不存在跨层连接.这样的神经网络结构通常称为`多层前馈神经网络`(multi-layer feedback neural networks),其中输入层神经元接收外接输入,隐层与输出层神经元对信号进行加工,最终结果由输出层神经元输出;换言之,输入层神经元仅是接受输入,不进行函数处理,隐层与输出层包含功能神经元.神经网络的学习过程,就是根据训练数据来调整神经元之间的'连接权'(connect weight)以及每个功能神经元的阈值;换言之,神经网络学到的东西,蕴含在连接权与阈值中.

## 误差逆传播算法

多层网络的徐诶能力比单层感知机强很多.误差逆传播算法,不仅可用于多层前缀神经网络,还可以用于其他类型的神经网络.

其工作流程:

输入: 训练集$$D=\{(x_k,y_k)\}_{k=1}^{m}$$; 学习率 $$\eta$$

```bash
过程:
在(0,1)范围内随机初始化网络中所有连接权和阈值
repeat
    for all(x_k,y_k) \in D do
        根据当前参数,计算当前样本的输出\hat{y_k}
        计算出输出层神经元的梯度项g_i
        计算隐层神经元的梯度项e_h
        更新连接权w_{hj},v_{ih}与阈值\theta_{j},\gamma_{h}
    end for
unitl达到停止条件

输出: 连接权与阈值确定的多层前馈神经网络
```

BP算法的目标是要最小化训练集D上的累计误差.

由于BP算法强大的表示能力,其经常遭遇过拟合,其训练误差持续降低,但测试误差可能上升.有两种策略用来环节BP网络的过拟合.

- 早停(early stopping):将数据分成训练集和验证集,训练集用来计算梯度,更新连接权和阈值,验证集用来估计误差,若训练集误差减低,但验证集误差升高,则停止训练,同时返回就有最小验证集误差的连接权和阈值.
- 正则化:其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分,例如连接权与阈值的平方和.

## 全局最小与局部极小

若用E表示神经网络在训练集上的误差,则它显然是关于连接权和阈值的函数.此时,神经网络的训练过程可看做一个参数寻有过程,即在参数空间中,寻找一组最优参数使E最小.

在现实任务中,人们常采用以下策略来试图跳出局部极小,从而进一步接近全局最小.

- 以多组不同参数值初始化多个神经网络,按标准方法训练后,取其中误差最小的解法作为最终参数.这相当于从多个不同的初始点开始搜索,这样就可能陷入不同的局部极小,从中进行选择有可能获得更接近全局最小的结果.
- 使用`模拟退火`simulated annealing技术.模拟退火在每一步都以一定的概率接受比当前更差的结果,从而有助于跳出局部极小.在每步迭代过程中,接受次优解的概率随着时间的推移而逐渐降低,从而保证算法稳定
- 使用随机梯度下降.与标准梯度下降法精确计算梯度不同,随梯度下降算法在计算梯度时加入了随机因素.于是,即便陷入局部极小点,它计算出的梯度仍可能不为零,这样就有机会跳出局部极小继续搜索.

此外,遗传算法(genetic algorithms)也常用来训练神经网络以更好地逼近全局最小.需要注意的是,上述跳出局部极小的技术大多是启发式,理论上尚缺乏保障.

## 其他常见神经网络

### RBF网络

RBF(Radial Basis Function,径向基函数)网络是一种单隐层前馈神经网络,它使用径向函数作为隐层神经元激活函数,而输出层则是对隐层神经元输出的线性组合.假定输入d维向量x,输出为实值,则RBF网络可表示为

$$\phi (x) = \sum_{i=1}^{q}w_{i}\rho(x,c_{i})$$

其中q为隐层神经元个数,$c_i$和$w_i$分别是第i个隐层神经元所对应的中心和权重$\rho(x,c_i)$是径向函数,这是某种沿径向对称的标量函数,通常定义为样本x到数据中心$c_i$之间欧式距离的单调函数.常用的高斯径向基函数形如

$$\rho(x,c_i) = e^{-\beta_i \left\| x-c_i \right\|^2}$$

具有足够多层神经元的RBF网络能以任意精度逼急任意连续函数.

通常采用两部过程来训练RBF网络:第一步,确定神经元中心$c_i$,常用的方式包括随机采样,聚类;第二步,利用BP算法等来确定参数$w_i$和$\beta_i$.

### ART网络

**竞争型学习**(competitive learning)是神经网络中一种常见的无监督学习策略,在使用该策略时,网络的输出神经元相互竞争,每一时刻仅有一个竞争获胜的神经元被激活,其他神经元的状态被抑制.这种机制亦称为(winner-take-all)原则.  

ART(Adaptive Resonance Theory,自适应谐振理论)网络是竞争型学习的重要代表.该网络由比较层,识别层,识别阈值和重置模块构成.其中,比较层负责接收输入样本,并将其传递给识别层神经元.识别层每个神经元对应一个模式类,神经元数目可在训练过程中动态增长以增加新的模式类.

- 在接收到比较层的输入信号后,识别层神经元之间相互竞争以产生获胜神经元.竞争的最简单方式是,计算输入量与每个识别层神经元所对应的模式类的代表向量之间的距离,记录最小者获胜.
- 获胜神经元将向其他识别层神经元发送信号,抑制其激活.若输入向量与获胜神经元所对应的代表向量之间的相似度大于识别阈值,则当前输入样本将被归为该代表向量所属类别,同时,网络连接权将会更新,使得以后再接收到相似输入样本时该模式类会计算出更大的相似度,从而使该获胜神经元有更大的可能获胜;若相似度不大于识别阈值,则重置模块将在识别层增设一个新的神经元,其代表向量就设置为当前输入向量.

> 显然,识别阈值对ART网络的性能有很重要的影响,当识别阈值较高时,输入样本会被分成比较多,比较精细的模式类,而如果识别阈值较低,则会产生比较少,比较粗略的模式类.

ART比较好的缓解了竞争型学习中的`可塑性-稳定性窘境(stability-plasticity dilemma)`,可塑性是指神经网络要有学习新知识的能力,而稳定性则是指神经网络在学习新知识时要保持对旧知识的记忆.这就使得ART网络具有一个很重要的优点:可进行增量学习(incremental learning)或在线学习(online learning).

早期的ART网络只能吃力布尔型输入数据,此后ART发展成了一个算法族,包括能处理实值输入的ART2网络,结合模糊处理的FuzzyART网络,以及可进行监督学习的ARTMAP网络等.

### SOM网络

SOM(Self-Organization Map, 自组织映射)网络是一种竞争学习型的无监督神经网络,它能将高维输入数据映射到低维空间,同时保持输入数据在高维空间的拓扑结构,即将高维空间中相似的样本点映射到网络输出层中的临近神经元.

SOM网络中输出层神经元以矩阵方式排列在二维空间中,每个神经元都拥有一个权向量,网络在接受输入向量后,将会确定输出层获胜神经元,它决定了该输入向量在低维空间中的位置.SOM的训练目标是就是为每个输出层神经元找到合适的权向量,以达到保持拓扑结构的目的.

SOM训练过程:在接收到一个训练样本后,每个输出层神经元会计算该样本与本身携带的权向量之间的距离,距离最近的神经元成为竞争获胜者,称为最佳匹配单元(best matching unit).然后,最佳匹配单元及其邻近神经元的权向量将被调整,以使得这些权向量与当前输入样本的距离缩小.这个过程不断迭代,直至收敛.

### 级联相关网络

一般的神经网络通常假定网络结构是事先固定的,训练的目的是利用训练样本来确定合适的连接权,阈值等参数.与此不同,结构自适应网络则将网络结构也当做学习目标之一,并希望能在训练过程中找到嘴和数据特点的网络结构.级联相关(Cascade-Correlation)网络是结构自适应网络的重要代表.

级联相关网络有两个主要成分'级联'和'相关'.级联是指建立层次链接的层级结构.在开始训练时,网络只有输入层和输出层,处于最小拓扑结构,随着训练进行,新的隐层神经元逐渐加入,从而创建起层级结构.当新的隐层神经元加入时,其输入端连接权值是冻结固定的.相关是指通过最大化神经元的输出与网络误差之间的相关性来训练相关参数.

**优点**:与一般的前馈神经网络相比,级联相关网络无需设置网络层数,隐层神经元,且训练速度快.  
**缺点**:在数据较小时易陷入过拟合.

### Elman网络

与前馈神经网络不同,**递归神经网络**(recurrent neural networks)允许网络中出现环形结构,从而可让一些神经元的输出反馈回来作为输入信号.这样的结构与信息返回过程,使得网络在t时刻的输出状态不仅与t时刻的输入有关还与t-1时刻的网络状态有关,从而能处理与时间有关的变动.

Elman网络是最常用的递归神经网络之一,它的结构与多层前馈网络很相似,但隐层神经元的输出被反馈回来,与下一时刻输入层神经元提供的信号一起,作为隐层神经元在下一时刻的输入.隐层神经元通常采用
Sigmoid激活函数,而网络的训练则常通过推广的BP算法进行.

### Boltzman机

神经网络中有一类模型是为网络状态定义一个'能量'能量最小化时网络达到理想状态,而网络的训练就是在最小化这个能量函数.  
Boltzman机就是一种基于能量的模型,其神经元分为两层:显层与隐层.显层用于表示数据的输入与输出,隐层则被理解为数据的内在表达.  
Boltzman中的神经元都是布尔型的,只能取0,1两种状态.

## 深度学习

理论上来说,参数越多的模型复杂度越高,容量越大,这意味着他能完成更复杂的学习任务.但一般情况下,复杂模型的训练效率低,易陷入过拟合,因此难以受到人们青睐.

